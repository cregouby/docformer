% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/supervised_model.R
\name{docformer_config}
\alias{docformer_config}
\title{Configuration for Docformer models}
\usage{
docformer_config(
  coordinate_size = 96L,
  shape_size = 96L,
  hidden_dropout_prob = 0.1,
  hidden_size = 768L,
  image_feature_pool_shape = c(7, 7, 256),
  intermediate_ff_size_factor = 3L,
  max_2d_position_embeddings = 1024L,
  max_position_embeddings = 512L,
  max_relative_positions = 8L,
  num_attention_heads = 12L,
  num_hidden_layers = 12L,
  pad_token_id = 1L,
  vocab_size = 30522L,
  layer_norm_eps = 1e-12,
  batch_size = 9L,
  pretraining_ratio = 0.5,
  verbose = FALSE,
  device = "auto"
)
}
\arguments{
\item{coordinate_size}{(int): Output size of each coordinate embedding (default 96)}

\item{shape_size}{(int): Output size of each position embedding (default 96)}

\item{hidden_dropout_prob}{(float): Dropout probability in docformer_encoder block (default 0.1)}

\item{hidden_size}{(int): Size of the hidden layer in common with text embedding and positional embedding (default 768)}

\item{image_feature_pool_shape}{(vector of 3 int): Shqpe of the image feature pooling (default c(7,7,256))}

\item{intermediate_ff_size_factor}{(int): Intermediate feed-forward layer expension factor (default 3)}

\item{max_2d_position_embeddings}{(int): Max size of vector hosting the 2D embedding (default 1024)}

\item{max_position_embeddings}{(int): Max sequence length for 1D embedding (default 512)}

\item{max_relative_positions}{(int): Max number of position to look at in multimodal attention layer (default 8)}

\item{num_attention_heads}{(int): Number of attention heads (default 12)}

\item{num_hidden_layers}{(int): Number of hidden layers in the encoder}

\item{pad_token_id}{(int): Id of the padding token}

\item{vocab_size}{(int): Length of the vocabulary}

\item{layer_norm_eps}{(float): Epsilon value used in normalisation layer (default 1e-12)}

\item{batch_size}{(int): Size of the batch (default 7)}

\item{pretraining_ratio}{(float): Ratio of features to mask for reconstruction during
pretraining.  Ranges from 0 to 1 (default=0.5)}

\item{verbose}{(bool): Whether to print progress and loss values during
training.}

\item{device}{The device to use for training. "cpu" or "cuda". The default ("auto")
uses  to "cuda" if it's available, otherwise uses "cpu".}
}
\value{
a named list will all needed hyperparameters of the Docformer implementation.
}
\description{
Configuration for Docformer models
}
\examples{
config <- docformer_config(num_attention_heads=6L, num_hidden_layers=6L, batch_size=27, verbose=TRUE)
}
